{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0     63    1   1       145   233    1        2      150      0      2.3   \n",
      "1     67    1   4       160   286    0        2      108      1      1.5   \n",
      "2     67    1   4       120   229    0        2      129      1      2.6   \n",
      "3     37    1   3       130   250    0        0      187      0      3.5   \n",
      "4     41    0   2       130   204    0        2      172      0      1.4   \n",
      "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "298   45    1   1       110   264    0        0      132      0      1.2   \n",
      "299   68    1   4       144   193    1        0      141      0      3.4   \n",
      "300   57    1   4       130   131    0        0      115      1      1.2   \n",
      "301   57    0   2       130   236    0        2      174      0      0.0   \n",
      "302   38    1   3       138   175    0        0      173      0      0.0   \n",
      "\n",
      "     slope   ca  thal  \n",
      "0        3  0.0   6.0  \n",
      "1        2  3.0   3.0  \n",
      "2        2  2.0   7.0  \n",
      "3        3  0.0   3.0  \n",
      "4        1  0.0   3.0  \n",
      "..     ...  ...   ...  \n",
      "298      2  0.0   7.0  \n",
      "299      2  2.0   7.0  \n",
      "300      2  1.0   7.0  \n",
      "301      2  1.0   3.0  \n",
      "302      1  NaN   3.0  \n",
      "\n",
      "[303 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubas\\AppData\\Local\\Temp\\ipykernel_9052\\825724569.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['thal'].fillna(value=mean_value_thal,inplace=True)\n",
      "C:\\Users\\kubas\\AppData\\Local\\Temp\\ipykernel_9052\\825724569.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ca'].fillna(value=mean_value_ca,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import numpy as np\n",
    "\n",
    "# fetch dataset\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = heart_disease.data.features\n",
    "print(X)\n",
    "y = heart_disease.data.targets\n",
    "\n",
    "y = np.where(y >= 1, 1, y)\n",
    "mean_value_thal=X['thal'].mean()\n",
    "X['thal'].fillna(value=mean_value_thal,inplace=True)\n",
    "mean_value_ca=X['ca'].mean()\n",
    "X['ca'].fillna(value=mean_value_ca,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = nan\n",
      "Epoch 1000: Loss = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubas\\AppData\\Local\\Temp\\ipykernel_9052\\1714926017.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
      "C:\\Users\\kubas\\AppData\\Local\\Temp\\ipykernel_9052\\1714926017.py:12: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000: Loss = nan\n",
      "Epoch 3000: Loss = nan\n",
      "Epoch 4000: Loss = nan\n",
      "Epoch 5000: Loss = nan\n",
      "Epoch 6000: Loss = nan\n",
      "Epoch 7000: Loss = nan\n",
      "Epoch 8000: Loss = nan\n",
      "Epoch 9000: Loss = nan\n",
      "Input: [0 0] Predicted Output: [[1.]]\n",
      "Input: [0 1] Predicted Output: [[1.]]\n",
      "Input: [1 0] Predicted Output: [[1.]]\n",
      "Input: [1 1] Predicted Output: [[1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Funkcja aktywacji - sigmoid\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "# Pochodna funkcji aktywacji sigmoid\n",
    "def softmax_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Funkcja kosztu - entropia krzyżowa\n",
    "def cross_entropy_loss(y, y_pred):\n",
    "    return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.num_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "\n",
    "        # Inicjalizacja wag i biasów dla wszystkich warstw\n",
    "        self.weights = [np.random.rand(layer_sizes[i - 1], layer_sizes[i]) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.zeros((1, layer_sizes[i])) for i in range(1, self.num_layers)]\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        # Propagacja w przód\n",
    "        layer_output = X\n",
    "        for i in range(self.num_layers - 1):\n",
    "            layer_input = np.dot(layer_output, self.weights[i]) + self.biases[i]\n",
    "            layer_output = softmax(layer_input)\n",
    "        return layer_output\n",
    "\n",
    "    def backpropagate(self, X, y, learning_rate):\n",
    "        # Obliczenie gradientów i aktualizacja wag i biasów wstecz\n",
    "        layer_outputs = [X]\n",
    "        layer_inputs = []\n",
    "        for i in range(self.num_layers - 1):\n",
    "            layer_input = np.dot(layer_outputs[i], self.weights[i]) + self.biases[i]\n",
    "            layer_inputs.append(layer_input)\n",
    "            layer_outputs.append(softmax(layer_input))\n",
    "\n",
    "        error = y - layer_outputs[-1]\n",
    "        delta = error * softmax_derivative(layer_outputs[-1])\n",
    "        for i in range(self.num_layers - 2, -1, -1):\n",
    "            self.weights[i] += layer_outputs[i].T.dot(delta) * learning_rate\n",
    "            self.biases[i] += np.sum(delta, axis=0, keepdims=True) * learning_rate\n",
    "            delta = delta.dot(self.weights[i].T) * softmax_derivative(layer_outputs[i])\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.feedforward(X)\n",
    "            loss = cross_entropy_loss(y, output)\n",
    "            self.backpropagate(X, y, learning_rate)\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}: Loss = {loss}\")\n",
    "\n",
    "# Przykładowe dane wejściowe\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Przykładowe dane wyjściowe\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Inicjalizacja i trening sieci neuronowej z trzema warstwami\n",
    "layer_sizes = [2, 4, 1]  # Liczba neuronów w kolejnych warstwach\n",
    "nn = NeuralNetwork(layer_sizes)\n",
    "nn.train(X, y, epochs=10000, learning_rate=0.1)\n",
    "\n",
    "# Testowanie sieci\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "for data_point in test_data:\n",
    "    prediction = nn.feedforward(data_point)\n",
    "    print(f\"Input: {data_point} Predicted Output: {prediction}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'MLP' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Podział danych na zbiór treningowy i testowy\u001B[39;00m\n\u001B[0;32m      4\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m MLP \u001B[38;5;241m=\u001B[39m \u001B[43mMLP\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m13\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m MLP\u001B[38;5;241m.\u001B[39mtrain(X_train, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m      7\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m MLP\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'MLP' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "MLP = MLP(input_size=13, hidden_layers=[10, 10], output_size=2)\n",
    "MLP.train(X_train, y_train, epochs=100, learning_rate=0.01)\n",
    "y_pred = MLP.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
